{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-09T03:50:02.285058Z","iopub.execute_input":"2023-04-09T03:50:02.285794Z","iopub.status.idle":"2023-04-09T03:50:02.322899Z","shell.execute_reply.started":"2023-04-09T03:50:02.285756Z","shell.execute_reply":"2023-04-09T03:50:02.321790Z"},"trusted":true},"execution_count":124,"outputs":[{"name":"stdout","text":"/kaggle/input/cleaned-dataset-my/cleaned.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Feature selection","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(\"/kaggle/input/cleaned-dataset-my/cleaned.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:50:02.324835Z","iopub.execute_input":"2023-04-09T03:50:02.326776Z","iopub.status.idle":"2023-04-09T03:50:04.434417Z","shell.execute_reply.started":"2023-04-09T03:50:02.326737Z","shell.execute_reply":"2023-04-09T03:50:04.433358Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"# Remove high dimentional columns\n\ndef get_categorical_columns(df):\n    \"\"\"\n    Takes a pandas DataFrame as input and identifies categorical columns. Outputs the number of categories in each column\n    and drops any columns with more than 20 categories. Returns the updated DataFrame.\n    \"\"\"\n    categorical_cols = df.select_dtypes(include=['category', 'object']).columns.tolist()\n    for col in categorical_cols:\n        if df[col].nunique() > 20:\n            df = df.drop(col, axis=1)\n            print(f\"Dropped column '{col}' because it had more than 20 categories.\")\n        else:\n            print(f\"Column '{col}' has {df[col].nunique()} categories.\")\n    return df\n\ndf = get_categorical_columns(df)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:50:04.435832Z","iopub.execute_input":"2023-04-09T03:50:04.436724Z","iopub.status.idle":"2023-04-09T03:50:05.964921Z","shell.execute_reply.started":"2023-04-09T03:50:04.436682Z","shell.execute_reply":"2023-04-09T03:50:05.963762Z"},"trusted":true},"execution_count":126,"outputs":[{"name":"stdout","text":"Column 'term' has 2 categories.\nColumn 'grade' has 7 categories.\nDropped column 'sub_grade' because it had more than 20 categories.\nDropped column 'emp_title' because it had more than 20 categories.\nColumn 'emp_length' has 11 categories.\nColumn 'home_ownership' has 6 categories.\nColumn 'verification_status' has 3 categories.\nDropped column 'issue_d' because it had more than 20 categories.\nColumn 'loan_status' has 6 categories.\nColumn 'pymnt_plan' has 2 categories.\nDropped column 'url' because it had more than 20 categories.\nColumn 'purpose' has 14 categories.\nDropped column 'title' because it had more than 20 categories.\nDropped column 'zip_code' because it had more than 20 categories.\nDropped column 'addr_state' because it had more than 20 categories.\nDropped column 'earliest_cr_line' because it had more than 20 categories.\nColumn 'initial_list_status' has 2 categories.\nColumn 'last_pymnt_d' has 7 categories.\nColumn 'next_pymnt_d' has 3 categories.\nDropped column 'last_credit_pull_d' because it had more than 20 categories.\nColumn 'application_type' has 2 categories.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom imblearn.over_sampling import SMOTE\n\ndef apply_feature_selection(df, target_col, k=15):\n    # separate features and target\n    X = df.drop(target_col, axis=1)\n    y = df[target_col]\n\n    # get numerical and categorical columns\n    num_cols = X.select_dtypes(include=['float', 'int']).columns.tolist()\n    cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n\n    # select features using SelectKBest and f_classif on numerical columns\n    selector = SelectKBest(score_func=f_classif, k=k)\n    X_num = X[num_cols]\n    X_num_new = selector.fit_transform(X_num, y)\n    selected_cols = selector.get_support(indices=True)\n    selected_features = X_num.columns[selected_cols]\n    X_num_selected = pd.DataFrame(X_num_new, columns=selected_features)\n\n    # concatenate numerical and categorical columns\n    X_new = pd.concat([X_num_selected, X[cat_cols]], axis=1)\n\n\n    # return preprocessed data as DataFrame\n    return pd.concat([X_new, y ], axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:50:05.968219Z","iopub.execute_input":"2023-04-09T03:50:05.968859Z","iopub.status.idle":"2023-04-09T03:50:05.979616Z","shell.execute_reply.started":"2023-04-09T03:50:05.968826Z","shell.execute_reply":"2023-04-09T03:50:05.978504Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"df_selected = apply_feature_selection(df, 'loan_status', k=15)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:50:05.981624Z","iopub.execute_input":"2023-04-09T03:50:05.982058Z","iopub.status.idle":"2023-04-09T03:50:06.543621Z","shell.execute_reply.started":"2023-04-09T03:50:05.982018Z","shell.execute_reply":"2023-04-09T03:50:06.542556Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"df_selected","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:50:06.545314Z","iopub.execute_input":"2023-04-09T03:50:06.545700Z","iopub.status.idle":"2023-04-09T03:50:06.755770Z","shell.execute_reply.started":"2023-04-09T03:50:06.545659Z","shell.execute_reply":"2023-04-09T03:50:06.754360Z"},"trusted":true},"execution_count":129,"outputs":[{"execution_count":129,"output_type":"execute_result","data":{"text/plain":"         int_rate  installment     annual_inc        dti  delinq_2yrs  \\\n0        6.620000   368.450000  105000.000000  14.050000     0.000000   \n1       12.618566   386.423936   67145.999461  18.741797     0.460752   \n2       12.618566   386.423936   67145.999461  18.741797     0.460752   \n3        9.670000   321.130000  102000.000000  15.550000     2.000000   \n4       12.618566   386.423936   67145.999461  18.741797     0.460752   \n...           ...          ...            ...        ...          ...   \n291305   6.490000   306.450000   75000.000000  33.660000     0.000000   \n291306  12.618566   386.423936   67145.999461  18.741797     0.460752   \n291307  12.618566   386.423936   67145.999461  18.741797     0.460752   \n291308  11.990000   797.030000   79000.000000   3.900000     0.000000   \n291309  12.618566   386.423936   67145.999461  18.741797     0.460752   \n\n        inq_last_6mths     revol_bal  revol_util  total_pymnt  \\\n0             1.000000  13168.000000   21.600000  8842.800000   \n1             0.445776  12664.435838   56.934101  3596.851282   \n2             0.445776  12664.435838   56.934101  3596.851282   \n3             0.000000   9912.000000   44.400000  7706.810000   \n4             0.445776  12664.435838   56.934101  3596.851282   \n...                ...           ...         ...          ...   \n291305        0.000000  10529.000000   34.700000  3670.190000   \n291306        0.445776  12664.435838   56.934101  3596.851282   \n291307        0.445776  12664.435838   56.934101  3596.851282   \n291308        1.000000   8621.000000   84.500000  9532.390000   \n291309        0.445776  12664.435838   56.934101  3596.851282   \n\n        total_pymnt_inv  ...  emp_length  home_ownership  verification_status  \\\n0           8842.800000  ...   10+ years        MORTGAGE         Not Verified   \n1           3595.528095  ...     2 years        MORTGAGE         Not Verified   \n2           3595.528095  ...     4 years            RENT         Not Verified   \n3           7706.810000  ...     7 years        MORTGAGE         Not Verified   \n4           3595.528095  ...     6 years        MORTGAGE      Source Verified   \n...                 ...  ...         ...             ...                  ...   \n291305      3670.190000  ...      1 year            RENT             Verified   \n291306      3595.528095  ...     8 years            RENT             Verified   \n291307      3595.528095  ...    < 1 year        MORTGAGE             Verified   \n291308      9532.390000  ...   10+ years        MORTGAGE             Verified   \n291309      3595.528095  ...      1 year            RENT      Source Verified   \n\n        pymnt_plan             purpose initial_list_status last_pymnt_d  \\\n0                n  debt_consolidation                   w     Jan-2016   \n1                n  debt_consolidation                   w     Jan-2016   \n2                n  debt_consolidation                   f     Jan-2016   \n3                n  debt_consolidation                   f     Jan-2016   \n4                n  debt_consolidation                   f     Jan-2016   \n...            ...                 ...                 ...          ...   \n291305           n  debt_consolidation                   w     Jan-2016   \n291306           n  debt_consolidation                   f     Jan-2016   \n291307           n         credit_card                   f     Jan-2016   \n291308           n    home_improvement                   f     Jan-2016   \n291309           n  debt_consolidation                   w     Jan-2016   \n\n       next_pymnt_d application_type loan_status  \n0          Feb-2016       INDIVIDUAL     Current  \n1          Feb-2016       INDIVIDUAL     Current  \n2          Feb-2016       INDIVIDUAL     Current  \n3          Feb-2016       INDIVIDUAL     Current  \n4          Feb-2016       INDIVIDUAL     Current  \n...             ...              ...         ...  \n291305     Feb-2016       INDIVIDUAL     Current  \n291306     Feb-2016       INDIVIDUAL     Current  \n291307     Feb-2016       INDIVIDUAL     Current  \n291308     Feb-2016       INDIVIDUAL     Current  \n291309     Feb-2016       INDIVIDUAL     Current  \n\n[291310 rows x 27 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>int_rate</th>\n      <th>installment</th>\n      <th>annual_inc</th>\n      <th>dti</th>\n      <th>delinq_2yrs</th>\n      <th>inq_last_6mths</th>\n      <th>revol_bal</th>\n      <th>revol_util</th>\n      <th>total_pymnt</th>\n      <th>total_pymnt_inv</th>\n      <th>...</th>\n      <th>emp_length</th>\n      <th>home_ownership</th>\n      <th>verification_status</th>\n      <th>pymnt_plan</th>\n      <th>purpose</th>\n      <th>initial_list_status</th>\n      <th>last_pymnt_d</th>\n      <th>next_pymnt_d</th>\n      <th>application_type</th>\n      <th>loan_status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6.620000</td>\n      <td>368.450000</td>\n      <td>105000.000000</td>\n      <td>14.050000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>13168.000000</td>\n      <td>21.600000</td>\n      <td>8842.800000</td>\n      <td>8842.800000</td>\n      <td>...</td>\n      <td>10+ years</td>\n      <td>MORTGAGE</td>\n      <td>Not Verified</td>\n      <td>n</td>\n      <td>debt_consolidation</td>\n      <td>w</td>\n      <td>Jan-2016</td>\n      <td>Feb-2016</td>\n      <td>INDIVIDUAL</td>\n      <td>Current</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>12.618566</td>\n      <td>386.423936</td>\n      <td>67145.999461</td>\n      <td>18.741797</td>\n      <td>0.460752</td>\n      <td>0.445776</td>\n      <td>12664.435838</td>\n      <td>56.934101</td>\n      <td>3596.851282</td>\n      <td>3595.528095</td>\n      <td>...</td>\n      <td>2 years</td>\n      <td>MORTGAGE</td>\n      <td>Not Verified</td>\n      <td>n</td>\n      <td>debt_consolidation</td>\n      <td>w</td>\n      <td>Jan-2016</td>\n      <td>Feb-2016</td>\n      <td>INDIVIDUAL</td>\n      <td>Current</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12.618566</td>\n      <td>386.423936</td>\n      <td>67145.999461</td>\n      <td>18.741797</td>\n      <td>0.460752</td>\n      <td>0.445776</td>\n      <td>12664.435838</td>\n      <td>56.934101</td>\n      <td>3596.851282</td>\n      <td>3595.528095</td>\n      <td>...</td>\n      <td>4 years</td>\n      <td>RENT</td>\n      <td>Not Verified</td>\n      <td>n</td>\n      <td>debt_consolidation</td>\n      <td>f</td>\n      <td>Jan-2016</td>\n      <td>Feb-2016</td>\n      <td>INDIVIDUAL</td>\n      <td>Current</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9.670000</td>\n      <td>321.130000</td>\n      <td>102000.000000</td>\n      <td>15.550000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>9912.000000</td>\n      <td>44.400000</td>\n      <td>7706.810000</td>\n      <td>7706.810000</td>\n      <td>...</td>\n      <td>7 years</td>\n      <td>MORTGAGE</td>\n      <td>Not Verified</td>\n      <td>n</td>\n      <td>debt_consolidation</td>\n      <td>f</td>\n      <td>Jan-2016</td>\n      <td>Feb-2016</td>\n      <td>INDIVIDUAL</td>\n      <td>Current</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12.618566</td>\n      <td>386.423936</td>\n      <td>67145.999461</td>\n      <td>18.741797</td>\n      <td>0.460752</td>\n      <td>0.445776</td>\n      <td>12664.435838</td>\n      <td>56.934101</td>\n      <td>3596.851282</td>\n      <td>3595.528095</td>\n      <td>...</td>\n      <td>6 years</td>\n      <td>MORTGAGE</td>\n      <td>Source Verified</td>\n      <td>n</td>\n      <td>debt_consolidation</td>\n      <td>f</td>\n      <td>Jan-2016</td>\n      <td>Feb-2016</td>\n      <td>INDIVIDUAL</td>\n      <td>Current</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>291305</th>\n      <td>6.490000</td>\n      <td>306.450000</td>\n      <td>75000.000000</td>\n      <td>33.660000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>10529.000000</td>\n      <td>34.700000</td>\n      <td>3670.190000</td>\n      <td>3670.190000</td>\n      <td>...</td>\n      <td>1 year</td>\n      <td>RENT</td>\n      <td>Verified</td>\n      <td>n</td>\n      <td>debt_consolidation</td>\n      <td>w</td>\n      <td>Jan-2016</td>\n      <td>Feb-2016</td>\n      <td>INDIVIDUAL</td>\n      <td>Current</td>\n    </tr>\n    <tr>\n      <th>291306</th>\n      <td>12.618566</td>\n      <td>386.423936</td>\n      <td>67145.999461</td>\n      <td>18.741797</td>\n      <td>0.460752</td>\n      <td>0.445776</td>\n      <td>12664.435838</td>\n      <td>56.934101</td>\n      <td>3596.851282</td>\n      <td>3595.528095</td>\n      <td>...</td>\n      <td>8 years</td>\n      <td>RENT</td>\n      <td>Verified</td>\n      <td>n</td>\n      <td>debt_consolidation</td>\n      <td>f</td>\n      <td>Jan-2016</td>\n      <td>Feb-2016</td>\n      <td>INDIVIDUAL</td>\n      <td>Current</td>\n    </tr>\n    <tr>\n      <th>291307</th>\n      <td>12.618566</td>\n      <td>386.423936</td>\n      <td>67145.999461</td>\n      <td>18.741797</td>\n      <td>0.460752</td>\n      <td>0.445776</td>\n      <td>12664.435838</td>\n      <td>56.934101</td>\n      <td>3596.851282</td>\n      <td>3595.528095</td>\n      <td>...</td>\n      <td>&lt; 1 year</td>\n      <td>MORTGAGE</td>\n      <td>Verified</td>\n      <td>n</td>\n      <td>credit_card</td>\n      <td>f</td>\n      <td>Jan-2016</td>\n      <td>Feb-2016</td>\n      <td>INDIVIDUAL</td>\n      <td>Current</td>\n    </tr>\n    <tr>\n      <th>291308</th>\n      <td>11.990000</td>\n      <td>797.030000</td>\n      <td>79000.000000</td>\n      <td>3.900000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>8621.000000</td>\n      <td>84.500000</td>\n      <td>9532.390000</td>\n      <td>9532.390000</td>\n      <td>...</td>\n      <td>10+ years</td>\n      <td>MORTGAGE</td>\n      <td>Verified</td>\n      <td>n</td>\n      <td>home_improvement</td>\n      <td>f</td>\n      <td>Jan-2016</td>\n      <td>Feb-2016</td>\n      <td>INDIVIDUAL</td>\n      <td>Current</td>\n    </tr>\n    <tr>\n      <th>291309</th>\n      <td>12.618566</td>\n      <td>386.423936</td>\n      <td>67145.999461</td>\n      <td>18.741797</td>\n      <td>0.460752</td>\n      <td>0.445776</td>\n      <td>12664.435838</td>\n      <td>56.934101</td>\n      <td>3596.851282</td>\n      <td>3595.528095</td>\n      <td>...</td>\n      <td>1 year</td>\n      <td>RENT</td>\n      <td>Source Verified</td>\n      <td>n</td>\n      <td>debt_consolidation</td>\n      <td>w</td>\n      <td>Jan-2016</td>\n      <td>Feb-2016</td>\n      <td>INDIVIDUAL</td>\n      <td>Current</td>\n    </tr>\n  </tbody>\n</table>\n<p>291310 rows × 27 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\ndef scale(df, target_col):\n    # separate features and target\n    X = df.drop(target_col, axis=1)\n    y = df[target_col]\n    \n    # perform feature scaling\n    scaler = StandardScaler()\n    numeric_cols = X.select_dtypes(include=['float64', 'int64']).columns\n    X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n    \n    return X , y\n    ","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:50:06.757334Z","iopub.execute_input":"2023-04-09T03:50:06.757855Z","iopub.status.idle":"2023-04-09T03:50:06.766128Z","shell.execute_reply.started":"2023-04-09T03:50:06.757811Z","shell.execute_reply":"2023-04-09T03:50:06.764881Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"X , y = scale(df, 'loan_status' )","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:50:06.767873Z","iopub.execute_input":"2023-04-09T03:50:06.768727Z","iopub.status.idle":"2023-04-09T03:50:06.967403Z","shell.execute_reply.started":"2023-04-09T03:50:06.768681Z","shell.execute_reply":"2023-04-09T03:50:06.966359Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ndef get_categorical_info(df):\n    # Get all the categorical columns\n    cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n\n    # For each categorical column, count the number of unique values and print if more than 50\n    for col in cat_cols:\n        n_unique = df[col].nunique()\n        if n_unique > 50:\n            print(f\"{col} has {n_unique} unique categories\")\n\nget_categorical_info(X)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:50:06.971594Z","iopub.execute_input":"2023-04-09T03:50:06.971918Z","iopub.status.idle":"2023-04-09T03:50:07.211087Z","shell.execute_reply.started":"2023-04-09T03:50:06.971888Z","shell.execute_reply":"2023-04-09T03:50:07.210060Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# print the shape of the training and testing sets\nprint(f\"X_train shape: {X_train.shape}\")\nprint(f\"X_test shape: {X_test.shape}\")\nprint(f\"y_train shape: {y_train.shape}\")\nprint(f\"y_test shape: {y_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:50:07.212660Z","iopub.execute_input":"2023-04-09T03:50:07.213012Z","iopub.status.idle":"2023-04-09T03:50:07.448369Z","shell.execute_reply.started":"2023-04-09T03:50:07.212975Z","shell.execute_reply":"2023-04-09T03:50:07.447261Z"},"trusted":true},"execution_count":133,"outputs":[{"name":"stdout","text":"X_train shape: (233048, 34)\nX_test shape: (58262, 34)\ny_train shape: (233048,)\ny_test shape: (58262,)\n","output_type":"stream"}]},{"cell_type":"code","source":"def process_y_train(y_train):\n    y_train = y_train.copy()\n    default_statuses = {'Late (16-30 days)', 'Late (31-120 days)', 'Default'}\n    y_train.replace(default_statuses, 'Default', inplace=True)\n    y_train.replace(y_train[y_train != 'Default'].unique(), 'Not Default', inplace=True)\n    return y_train\n\n\ny_train = process_y_train(y_train)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:50:07.449834Z","iopub.execute_input":"2023-04-09T03:50:07.450314Z","iopub.status.idle":"2023-04-09T03:50:07.534474Z","shell.execute_reply.started":"2023-04-09T03:50:07.450249Z","shell.execute_reply":"2023-04-09T03:50:07.533438Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"code","source":"def process_y_train(y_train):\n    y_train = y_train.copy()\n    default_statuses = {'Late (16-30 days)', 'Late (31-120 days)', 'Default'}\n    y_train.replace(default_statuses, 'Default', inplace=True)\n    y_train.replace(y_train[y_train != 'Default'].unique(), 'Not Default', inplace=True)\n    return y_train\n\n\ny_test = process_y_train(y_test)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:50:07.536009Z","iopub.execute_input":"2023-04-09T03:50:07.536379Z","iopub.status.idle":"2023-04-09T03:50:07.566425Z","shell.execute_reply.started":"2023-04-09T03:50:07.536341Z","shell.execute_reply":"2023-04-09T03:50:07.565485Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"code","source":"# One hot encoding\nX_train = pd.get_dummies(X_train)\nX_test = pd.get_dummies(X_test)\ny_train = pd.get_dummies(y_train)\ny_test = pd.get_dummies(y_test)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:50:07.569490Z","iopub.execute_input":"2023-04-09T03:50:07.569759Z","iopub.status.idle":"2023-04-09T03:50:07.929976Z","shell.execute_reply.started":"2023-04-09T03:50:07.569733Z","shell.execute_reply":"2023-04-09T03:50:07.928949Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"def remove_additional_columns(X_train, X_test):\n    # Check if number of columns in X_train and X_test are equal\n    if X_train.shape[1] != X_test.shape[1]:\n        # Find additional columns in X_train\n        extra_train_columns = set(X_train.columns) - set(X_test.columns)\n        # Remove additional columns from X_train\n        X_train = X_train.drop(columns=extra_train_columns)\n        \n        # Find additional columns in X_test\n        extra_test_columns = set(X_test.columns) - set(X_train.columns)\n        # Remove additional columns from X_test\n        X_test = X_test.drop(columns=extra_test_columns)\n        \n    return X_train, X_test\n\nX_train, X_test = remove_additional_columns(X_train, X_test)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:50:07.931482Z","iopub.execute_input":"2023-04-09T03:50:07.931829Z","iopub.status.idle":"2023-04-09T03:50:07.976466Z","shell.execute_reply.started":"2023-04-09T03:50:07.931790Z","shell.execute_reply":"2023-04-09T03:50:07.975231Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:50:07.977937Z","iopub.execute_input":"2023-04-09T03:50:07.978859Z","iopub.status.idle":"2023-04-09T03:50:07.991653Z","shell.execute_reply.started":"2023-04-09T03:50:07.978816Z","shell.execute_reply":"2023-04-09T03:50:07.990364Z"},"trusted":true},"execution_count":138,"outputs":[{"execution_count":138,"output_type":"execute_result","data":{"text/plain":"        Default  Not Default\n245294        0            1\n264277        0            1\n148436        0            1\n198460        0            1\n149291        0            1\n...         ...          ...\n119879        0            1\n259178        0            1\n131932        0            1\n146867        0            1\n121958        0            1\n\n[233048 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Default</th>\n      <th>Not Default</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>245294</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>264277</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>148436</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>198460</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>149291</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>119879</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>259178</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>131932</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>146867</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>121958</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>233048 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Model Building","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\ndef build_classification_models(X_train, y_train, X_test, y_test):\n    models = {}\n    \n    # Random Forest Classifier\n    rf = RandomForestClassifier()\n    rf.fit(X_train, y_train)\n    models['Random Forest'] = rf\n    \n    dt = DecisionTreeClassifier()\n    dt.fit(X_train, y_train)\n    models['Decision Tree'] = dt\n    \n    # Evaluate models on testing data\n    scores = {}\n    for name, model in models.items():\n        y_pred = model.predict(X_test)\n        scores[name] = {\n            'Accuracy': accuracy_score(y_test, y_pred),\n            'Precision': precision_score(y_test, y_pred, average='weighted'),\n            'Recall': recall_score(y_test, y_pred, average='weighted'),\n            'F1': f1_score(y_test, y_pred, average='weighted')\n        }\n        \n    # sort results by F1 score in ascending order\n    sorted_scores = sorted(scores.items(), key=lambda x: x[1]['F1'])\n    \n    return sorted_scores, models\n","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:50:07.994050Z","iopub.execute_input":"2023-04-09T03:50:07.995502Z","iopub.status.idle":"2023-04-09T03:50:08.005748Z","shell.execute_reply.started":"2023-04-09T03:50:07.995470Z","shell.execute_reply":"2023-04-09T03:50:08.004809Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"code","source":"sorted_scores, models=  build_classification_models(X_train, y_train, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:50:08.006749Z","iopub.execute_input":"2023-04-09T03:50:08.006991Z","iopub.status.idle":"2023-04-09T03:51:19.748635Z","shell.execute_reply.started":"2023-04-09T03:50:08.006968Z","shell.execute_reply":"2023-04-09T03:51:19.747475Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"sorted_scores","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:51:19.750289Z","iopub.execute_input":"2023-04-09T03:51:19.750678Z","iopub.status.idle":"2023-04-09T03:51:19.758242Z","shell.execute_reply.started":"2023-04-09T03:51:19.750635Z","shell.execute_reply":"2023-04-09T03:51:19.757113Z"},"trusted":true},"execution_count":141,"outputs":[{"execution_count":141,"output_type":"execute_result","data":{"text/plain":"[('Decision Tree',\n  {'Accuracy': 0.9865778723696406,\n   'Precision': 0.9869011703870906,\n   'Recall': 0.9865778723696406,\n   'F1': 0.9865612493139816}),\n ('Random Forest',\n  {'Accuracy': 0.9910919638872678,\n   'Precision': 0.9909633525363641,\n   'Recall': 0.9910919638872678,\n   'F1': 0.9902750444861365})]"},"metadata":{}}]},{"cell_type":"markdown","source":"#### The best model is random forest","metadata":{}},{"cell_type":"code","source":"models","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:52:17.740340Z","iopub.execute_input":"2023-04-09T03:52:17.740901Z","iopub.status.idle":"2023-04-09T03:52:17.750323Z","shell.execute_reply.started":"2023-04-09T03:52:17.740855Z","shell.execute_reply":"2023-04-09T03:52:17.749258Z"},"trusted":true},"execution_count":146,"outputs":[{"execution_count":146,"output_type":"execute_result","data":{"text/plain":"{'Random Forest': RandomForestClassifier(),\n 'Decision Tree': DecisionTreeClassifier()}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Model optimization","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\n\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [None, 5, 10, 20],\n    'min_samples_split': [2, 5, 10]\n}\n\n\ndef build_best_rf_model(X_train, y_train, X_test, y_test, param_grid):\n    # Initialize a random forest classifier object\n    rf = RandomForestClassifier()\n    \n    # Perform grid search to find the best hyperparameters\n    grid_search = GridSearchCV(rf, param_grid, cv=5)\n    grid_search.fit(X_train, y_train)\n    \n    # Get the best hyperparameters and their corresponding score\n    best_params = grid_search.best_params_\n    best_score = grid_search.best_score_\n    \n    # Train a new random forest model using the best hyperparameters\n    best_rf_model = RandomForestClassifier(**best_params)\n    best_rf_model.fit(X_train, y_train)\n    \n    # Evaluate the best model on the testing data\n    y_pred = best_rf_model.predict(X_test)\n    scores = {\n        'Accuracy': accuracy_score(y_test, y_pred),\n        'Precision': precision_score(y_test, y_pred, average='weighted'),\n        'Recall': recall_score(y_test, y_pred, average='weighted'),\n        'F1': f1_score(y_test, y_pred, average='weighted')\n    }\n    \n    return best_params, best_score, best_rf_model, scores\n","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:51:19.759902Z","iopub.execute_input":"2023-04-09T03:51:19.760580Z","iopub.status.idle":"2023-04-09T03:51:19.770923Z","shell.execute_reply.started":"2023-04-09T03:51:19.760540Z","shell.execute_reply":"2023-04-09T03:51:19.770268Z"},"trusted":true},"execution_count":142,"outputs":[]},{"cell_type":"code","source":"# since , our model accuracy is above 90%, no need to hyper perameter optimization\n'''best_params, best_score, best_rf_model, scores= build_best_rf_model(X_train, y_train, X_test, y_test, param_grid)'''","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:51:19.772181Z","iopub.execute_input":"2023-04-09T03:51:19.772802Z","iopub.status.idle":"2023-04-09T03:51:19.787970Z","shell.execute_reply.started":"2023-04-09T03:51:19.772756Z","shell.execute_reply":"2023-04-09T03:51:19.786953Z"},"trusted":true},"execution_count":143,"outputs":[{"execution_count":143,"output_type":"execute_result","data":{"text/plain":"'best_params, best_score, best_rf_model, scores= build_best_rf_model(X_train, y_train, X_test, y_test, param_grid)'"},"metadata":{}}]},{"cell_type":"code","source":"import joblib","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:51:19.790169Z","iopub.execute_input":"2023-04-09T03:51:19.790884Z","iopub.status.idle":"2023-04-09T03:51:19.795253Z","shell.execute_reply.started":"2023-04-09T03:51:19.790849Z","shell.execute_reply":"2023-04-09T03:51:19.794133Z"},"trusted":true},"execution_count":144,"outputs":[]},{"cell_type":"code","source":"# Save the trained model\njoblib.dump(models['Random Forest'], 'random_forest_model.joblib')","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:52:44.560024Z","iopub.execute_input":"2023-04-09T03:52:44.560717Z","iopub.status.idle":"2023-04-09T03:52:44.709938Z","shell.execute_reply.started":"2023-04-09T03:52:44.560679Z","shell.execute_reply":"2023-04-09T03:52:44.708786Z"},"trusted":true},"execution_count":147,"outputs":[{"execution_count":147,"output_type":"execute_result","data":{"text/plain":"['random_forest_model.joblib']"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}